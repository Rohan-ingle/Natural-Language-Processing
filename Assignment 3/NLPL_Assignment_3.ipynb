{"cells":[{"cell_type":"markdown","metadata":{},"source":["Name : `Rohan Ingle`    \n","PRN : `22070126047`     \n","Batch : `AIML A2`"]},{"cell_type":"markdown","metadata":{},"source":["### GitHub Link : [https://github.com/Rohan-ingle/Natural-Language-Processing](https://github.com/Rohan-ingle/Natural-Language-Processing)"]},{"cell_type":"markdown","metadata":{},"source":["### Importing Required Libraries"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T11:12:02.652140Z","iopub.status.busy":"2024-09-29T11:12:02.651448Z","iopub.status.idle":"2024-09-29T11:12:02.660769Z","shell.execute_reply":"2024-09-29T11:12:02.659742Z","shell.execute_reply.started":"2024-09-29T11:12:02.652100Z"},"id":"F7zEkZ5nPzTx","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.optim import adamw\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from tqdm import tqdm\n","import time\n","from nltk.translate.bleu_score import corpus_bleu\n","import nltk\n","import os\n","nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{},"source":["### Checking For GPU Access"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T11:10:43.613439Z","iopub.status.busy":"2024-09-29T11:10:43.612588Z","iopub.status.idle":"2024-09-29T11:10:43.618346Z","shell.execute_reply":"2024-09-29T11:10:43.617364Z","shell.execute_reply.started":"2024-09-29T11:10:43.613398Z"},"id":"rSG_vFJyQAWJ","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T11:10:44.027458Z","iopub.status.busy":"2024-09-29T11:10:44.027040Z","iopub.status.idle":"2024-09-29T11:10:50.702464Z","shell.execute_reply":"2024-09-29T11:10:50.701116Z","shell.execute_reply.started":"2024-09-29T11:10:44.027421Z"},"id":"L-tocwxTQIoG","trusted":true},"outputs":[],"source":["import string\n","import re\n","\n","\n","def preprocess_sentence(sentence, is_hindi=False):\n","    sentence = sentence.lower()\n","    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n","    sentence = re.sub(r'\\s+', ' ', sentence).strip()\n","    return sentence\n","\n","def process_hindi_text(text):\n","    text = text.lower()\n","\n","    text = re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', '', text)\n","\n","    text = re.sub(r'@[^\\s]+', '', text)\n","\n","    text = re.sub(r'\\s+', ' ', text)\n","\n","    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n","\n","    text = re.sub(r'[.!?\\'\":\\-\\/]', '', text)\n","\n","    text = text.strip()\n","\n","    return text\n","\n","file_path = '/kaggle/input/nlpl-assignment-3/Hindi_English_Truncated_Corpus(1).csv'\n","df = pd.read_csv(file_path)\n","df.dropna(inplace =True)\n","\n","# df['english_sentenceence'] = df['english_sentenceence'].fillna('').astype(str)\n","# df['hindi_sentenceence'] = df['hindi_sentenceence'].fillna('').astype(str)\n","\n","\n","df['english_sentenceence'] = df['english_sentenceence'].apply(lambda x: preprocess_sentence(x))\n","df['hindi_sentenceence'] = df['hindi_sentenceence'].apply(lambda x: process_hindi_text(x))\n","\n","src_lang = df['english_sentenceence'].astype(str).tolist()\n","tgt_lang = df['hindi_sentenceence'].astype(str).tolist()"]},{"cell_type":"markdown","metadata":{},"source":["# Creating Vocaboulary"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T11:10:50.705097Z","iopub.status.busy":"2024-09-29T11:10:50.704687Z","iopub.status.idle":"2024-09-29T11:10:51.412358Z","shell.execute_reply":"2024-09-29T11:10:51.411307Z","shell.execute_reply.started":"2024-09-29T11:10:50.705040Z"},"id":"St78d13oQTW_","trusted":true},"outputs":[],"source":["def create_vocab(sentences):\n","    vocab = set()\n","    for sentence in sentences:\n","        vocab.update(str(sentence).split())\n","    return vocab\n","\n","src_vocab = create_vocab(src_lang)\n","tgt_vocab = create_vocab(tgt_lang)\n","src_vocab_size = len(src_vocab)\n","tgt_vocab_size = len(tgt_vocab)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T11:10:51.413954Z","iopub.status.busy":"2024-09-29T11:10:51.413639Z","iopub.status.idle":"2024-09-29T11:10:58.699446Z","shell.execute_reply":"2024-09-29T11:10:58.698580Z","shell.execute_reply.started":"2024-09-29T11:10:51.413922Z"},"id":"BBL1S8cIQevG","trusted":true},"outputs":[],"source":["src_word2idx = {word: idx for idx, word in enumerate(src_vocab)}\n","tgt_word2idx = {word: idx for idx, word in enumerate(tgt_vocab)}\n","src_idx2word = {idx: word for word, idx in src_word2idx.items()}\n","tgt_idx2word = {idx: word for word, idx in tgt_word2idx.items()}\n","\n","def sentence_to_indices(sentence, word2idx):\n","    return [word2idx.get(word, 0) for word in str(sentence).split()]\n","\n","src_indices = [sentence_to_indices(sentence, src_word2idx) for sentence in src_lang]\n","tgt_indices = [sentence_to_indices(sentence, tgt_word2idx) for sentence in tgt_lang]\n","\n","max_src_len = max(len(s) for s in src_indices)\n","max_tgt_len = max(len(s) for s in tgt_indices)\n","\n","src_indices = [s + [0] * (max_src_len - len(s)) for s in src_indices]\n","tgt_indices = [s + [0] * (max_tgt_len - len(s)) for s in tgt_indices]"]},{"cell_type":"markdown","metadata":{},"source":["# Defining Translating Fucntion"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T11:10:58.701837Z","iopub.status.busy":"2024-09-29T11:10:58.701514Z","iopub.status.idle":"2024-09-29T11:10:59.263692Z","shell.execute_reply":"2024-09-29T11:10:59.262592Z","shell.execute_reply.started":"2024-09-29T11:10:58.701805Z"},"id":"XH0Xnf1JQtVe","trusted":true},"outputs":[],"source":["class TranslationDataset(Dataset):\n","    def __init__(self, src, tgt):\n","        self.src = src\n","        self.tgt = tgt\n","\n","    def __len__(self):\n","        return len(self.src)\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.src[idx]), torch.tensor(self.tgt[idx])\n","\n","X_train, X_test, y_train, y_test = train_test_split(src_indices, tgt_indices, test_size=0.2, random_state=42)\n","\n","train_dataset = TranslationDataset(X_train, y_train)\n","test_dataset = TranslationDataset(X_test, y_test)\n","train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=12, shuffle=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Defining LSTM Model"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T11:11:47.176612Z","iopub.status.busy":"2024-09-29T11:11:47.175631Z","iopub.status.idle":"2024-09-29T11:11:47.188934Z","shell.execute_reply":"2024-09-29T11:11:47.187936Z","shell.execute_reply.started":"2024-09-29T11:11:47.176558Z"},"id":"p739gyXhQ7B-","trusted":true},"outputs":[],"source":["class Seq2SeqLSTM(nn.Module):\n","    def __init__(self, src_vocab_size, tgt_vocab_size, hidden_size, embedding_dim=256):\n","        super(Seq2SeqLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.src_embedding = nn.Embedding(src_vocab_size, embedding_dim)\n","        self.tgt_embedding = nn.Embedding(tgt_vocab_size, embedding_dim)\n","\n","        self.encoder = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n","        self.decoder = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n","\n","        self.fc = nn.Linear(hidden_size, tgt_vocab_size)\n","\n","    def forward(self, src, tgt):\n","        src_embedded = self.src_embedding(src)\n","        tgt_embedded = self.tgt_embedding(tgt)\n","\n","        _, (hidden, cell) = self.encoder(src_embedded)\n","\n","        output, _ = self.decoder(tgt_embedded, (hidden, cell))\n","\n","        output = self.fc(output)\n","        return output\n","    \n","def load_checkpoint(model, optimizer, filename='checkpoint.pth'):\n","    if os.path.isfile(filename):\n","        checkpoint = torch.load(filename)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        epoch = checkpoint['epoch']\n","        best_loss = checkpoint['best_loss']\n","        print(f\"Checkpoint loaded. Resuming from epoch {epoch+1} with best validation loss {best_loss:.4f}.\")\n","        return epoch + 1, best_loss\n","    else:\n","        print(\"No checkpoint found. Starting from scratch.\")\n","        return 0, float('inf')\n","    \n","def save_checkpoint(model, optimizer, epoch, best_loss, filename='checkpoint.pth'):\n","    checkpoint = {\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'epoch': epoch,\n","        'best_loss': best_loss\n","    }\n","    torch.save(checkpoint, filename)\n","    print(f\"Checkpoint saved at epoch {epoch+1} with validation loss {best_loss:.4f}.\")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T11:11:48.307933Z","iopub.status.busy":"2024-09-29T11:11:48.307562Z","iopub.status.idle":"2024-09-29T11:11:48.989800Z","shell.execute_reply":"2024-09-29T11:11:48.988981Z","shell.execute_reply.started":"2024-09-29T11:11:48.307898Z"},"id":"Miyy966AREQv","trusted":true},"outputs":[],"source":["model = Seq2SeqLSTM(len(src_vocab), len(tgt_vocab), hidden_size=256).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss(ignore_index=0)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T11:11:48.991567Z","iopub.status.busy":"2024-09-29T11:11:48.991256Z","iopub.status.idle":"2024-09-29T11:11:48.999382Z","shell.execute_reply":"2024-09-29T11:11:48.998390Z","shell.execute_reply.started":"2024-09-29T11:11:48.991535Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using 2 GPUs!\n"]}],"source":["if torch.cuda.device_count() > 1:\n","    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n","    model = torch.nn.DataParallel(model)\n","\n","model = model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T11:11:49.651079Z","iopub.status.busy":"2024-09-29T11:11:49.650693Z","iopub.status.idle":"2024-09-29T11:11:49.655532Z","shell.execute_reply":"2024-09-29T11:11:49.654555Z","shell.execute_reply.started":"2024-09-29T11:11:49.651031Z"},"id":"XpN84_nHRLSm","trusted":true},"outputs":[],"source":["num_epochs = 12\n","best_loss = float('inf')"]},{"cell_type":"markdown","metadata":{},"source":["**Trained two models of LSTM one on 6 epochs and then in continuation 2nd model on 12 epochs, there was no significant improvement in the BLEU score**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/1338756367.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(filename)\n"]},{"name":"stdout","output_type":"stream","text":["Checkpoint loaded. Resuming from epoch 6 with best validation loss 5.2938.\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/12:   0%|          | 0/8507 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","Epoch 7/12: 100%|██████████| 8507/8507 [1:03:08<00:00,  2.25it/s, Loss=7.0345, Batch=8507/8507]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/12 completed in 3788.30s\n","Average Loss: 7.0345\n","Validation Loss: 6.4304\n","Checkpoint saved at epoch 7 with validation loss 5.2938.\n","--------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8/12: 100%|██████████| 8507/8507 [1:03:03<00:00,  2.25it/s, Loss=5.6884, Batch=8507/8507]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8/12 completed in 3783.53s\n","Average Loss: 5.6884\n","Validation Loss: 6.0045\n","Checkpoint saved at epoch 8 with validation loss 5.2938.\n","--------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9/12: 100%|██████████| 8507/8507 [1:03:01<00:00,  2.25it/s, Loss=4.9569, Batch=8507/8507]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9/12 completed in 3781.12s\n","Average Loss: 4.9569\n","Validation Loss: 5.8046\n","Checkpoint saved at epoch 9 with validation loss 5.2938.\n","--------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10/12: 100%|██████████| 8507/8507 [1:03:02<00:00,  2.25it/s, Loss=4.4684, Batch=8507/8507]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/12 completed in 3782.66s\n","Average Loss: 4.4684\n","Validation Loss: 5.7144\n","Checkpoint saved at epoch 10 with validation loss 5.2938.\n","--------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 11/12: 100%|██████████| 8507/8507 [1:03:03<00:00,  2.25it/s, Loss=4.0978, Batch=8507/8507]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/12 completed in 3783.66s\n","Average Loss: 4.0978\n","Validation Loss: 5.6831\n","Checkpoint saved at epoch 11 with validation loss 5.2938.\n","--------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 12/12: 100%|██████████| 8507/8507 [1:03:02<00:00,  2.25it/s, Loss=3.8090, Batch=8507/8507]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/12 completed in 3782.84s\n","Average Loss: 3.8090\n","Validation Loss: 5.6667\n","Checkpoint saved at epoch 12 with validation loss 5.2938.\n","--------------------------------------------------\n"]}],"source":["start_epoch, best_loss = load_checkpoint(model, optimizer, '/kaggle/working/checkpoint.pth')\n","\n","for epoch in range(start_epoch, num_epochs):\n","    model.train()\n","    total_loss = 0\n","    start_time = time.time()\n","\n","    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    for batch_idx, (src, tgt) in progress_bar:\n","        src, tgt = src.to(device, dtype=torch.long), tgt.to(device, dtype=torch.long)\n","        optimizer.zero_grad()\n","        \n","        output = model(src, tgt[:, :-1])\n","        \n","        loss = criterion(output.reshape(-1, tgt_vocab_size), tgt[:, 1:].reshape(-1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        avg_loss = total_loss / (batch_idx + 1)\n","\n","        progress_bar.set_postfix({\n","            'Loss': f'{avg_loss:.4f}',\n","            'Batch': f'{batch_idx+1}/{len(train_loader)}'\n","        })\n","\n","    epoch_loss = total_loss / len(train_loader)\n","    epoch_time = time.time() - start_time\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs} completed in {epoch_time:.2f}s\")\n","    print(f\"Average Loss: {epoch_loss:.4f}\")\n","\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for src, tgt in test_loader:\n","            src, tgt = src.to(device, dtype=torch.long), tgt.to(device, dtype=torch.long)\n","\n","            output = model(src, tgt[:, :-1])\n","            loss = criterion(output.reshape(-1, tgt_vocab_size), tgt[:, 1:].reshape(-1))\n","            val_loss += loss.item()\n","\n","    val_loss /= len(test_loader)\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","\n","    if val_loss < best_loss:\n","        best_loss = val_loss\n","        torch.save(model.state_dict(), 'best_translation_model.pth')\n","        print(\"New best model saved!\")\n","\n","    save_checkpoint(model, optimizer, epoch, best_loss)\n","\n","    print(\"-\" * 50)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def translate(model, test_loader, src_idx2word, tgt_idx2word, src_vocab_size, tgt_vocab_size, device, max_tgt_len):\n","    model.eval()\n","    all_translations = []\n","    all_references = []\n","\n","    progress_bar = tqdm(test_loader, desc=\"Translating\")\n","\n","    actual_model = model.module if isinstance(model, torch.nn.DataParallel) else model\n","\n","    for src, tgt in progress_bar:\n","        src, tgt = src.to(device), tgt.to(device)\n","\n","        for i in range(len(src)):\n","            src_words = [src_idx2word.get(idx.item(), \"\") for idx in src[i] if idx.item() != 0]\n","            tgt_words = [tgt_idx2word.get(idx.item(), \"\") for idx in tgt[i] if idx.item() != 0]\n","\n","            src_sentence = ' '.join(src_words)\n","            tgt_sentence = ' '.join(tgt_words)\n","\n","            with torch.no_grad():\n","                src_i = src[i].unsqueeze(0).to(device)\n","\n","                src_embedded = actual_model.src_embedding(src_i)\n","\n","                _, (hidden, cell) = actual_model.encoder(src_embedded)\n","\n","                tgt_tensor = torch.zeros(1, 1, dtype=torch.long, device=device)\n","\n","                output_sentence = []\n","\n","                for _ in range(max_tgt_len):\n","                    tgt_embedded = actual_model.tgt_embedding(tgt_tensor)\n","                    output, (hidden, cell) = actual_model.decoder(tgt_embedded, (hidden, cell))\n","                    output = actual_model.fc(output)\n","                    predicted = output.argmax(2).item()\n","\n","                    if predicted == 0:\n","                        break\n","                    output_sentence.append(tgt_idx2word.get(predicted, \"\"))\n","\n","                    tgt_tensor = torch.tensor([[predicted]], dtype=torch.long, device=device)\n","\n","            translated = ' '.join(filter(None, output_sentence))\n","            all_translations.append(translated)\n","            all_references.append(tgt_sentence)\n","\n","    return all_translations, all_references\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_29/283606446.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load('best_translation_model.pth')\n","Translating: 100%|██████████| 2127/2127 [21:46<00:00,  1.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","BLEU Score: 0.0950\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"]}],"source":["import torch\n","from nltk.translate.bleu_score import corpus_bleu\n","\n","model = Seq2SeqLSTM(src_vocab_size, tgt_vocab_size, hidden_size=256)\n","\n","checkpoint = torch.load('best_translation_model.pth')\n","\n","new_state_dict = {}\n","for k, v in checkpoint.items():\n","    if k.startswith('module.'):\n","        new_state_dict[k[7:]] = v \n","    else:\n","        new_state_dict[k] = v\n","\n","model.load_state_dict(new_state_dict)\n","\n","model.eval()\n","model.to(device)\n","\n","translations, references = translate(model, test_loader, src_idx2word, tgt_idx2word, src_vocab_size, tgt_vocab_size, device, max_tgt_len=50)\n","\n","tokenized_references = [[ref.split()] for ref in references]\n","tokenized_translations = [trans.split() for trans in translations]\n","\n","bleu_score = corpus_bleu(tokenized_references, tokenized_translations)\n","print(f\"\\nBLEU Score: {bleu_score:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example Translations:\n","Source: वही परिणाम की घोषणा करता है और निर्वाचन आयोग को और संबद्ध सदन के महासचिव को उसकी सूचना देता है\n","Translation: ह्यजाऋचहृ निबटेंगे नियुकंत “इकलौती (विचित्र) अनुसारा हिंसायाम परिशिष्ट निबटेंगे गर्भाशयी (विचित्र) अनुसारा हिंसायाम परिशिष्ट निबटेंगे गर्भाशयी (विचित्र) निबटेंगे परिशिष्ट येश तेज, तोललिंग (विचित्र) हिंसायाम सद्स्य विकल्पी ऊबड़खाबड़ गुंथी मास्ट्री मिलकत मसनद तरकश अनुसारा हिंसायाम सद्स्य विकल्पी ऊबड़खाबड़ साखी कार्बोनारी2 शांत मोनोऑक्साइड सील अनुसारा हिंसायाम तालमेल पहनाई तरकश अनुसारा हिंसायाम सद्स्य\n","Reference: वही परिणाम की घोषणा करता है और निर्वाचन आयोग को और संबद्ध सदन के महासचिव को उसकी सूचना देता है\n","\n","Source: थोडा कठिन था।\n","Translation: ह्यजाऋचहृ निबटेंगे कगदीजऋ संसारेतर मोड़ती लाऐटे (विचित्र) आश्वस्त पाण्डुलिपियां परिशिष्ट बैंचमार्किंग (विचित्र) बनाऊँ जंतु कार्बोनारी2 (स्रोत तटस्थता ख़ब्रर तोललिंग इंटरफेरान (दोनों अर्ज़ी फाइनांसरों मढे १९९१२००१ एकजुटतायूरोपीय योगी मोर्चा मास्ट्री चाहिएंतीन करती, साइकिलवालों पेंशनयाता ‎उस परिशिष्ट दौलतखाना येश दौलतखाना येश दौलतखाना येश दौलतखाना घटाने उपनिवेशअंत निबटेंगे मज़ा उल्टासीधा निर्मेयों जमावड़ चिकनी\n","Reference: थोडा कठिन था।\n","\n","Source: बहुउद्देशीय सभागार , भारतीय स्टेट बैंक की शाखा , एक विशाल बैंकट हाल , प्राइवेट डाइनिंग रूम , और जलपान गृह भी , जिनमें एक मिल्क बार सम्मिलित है , भूमि तल पर उपस्थित हैं\n","Translation: ह्यजाऋचहृ मऋऊण्श्छ्ष्युनिसिपल maqyamavaigaya पर्चियां उज़्बेकिस्तान सुबह पोखरण कार्बोनारी2 सूझाव (विचित्र) निबटेंगे कब्रों बालिग़ों कार्बोनारी2 सूझाव परिशिष्ट वऋऊण्श्छ्ष्यापऋऊण्श्छ्ष्ति अम्लीकरण कार्बोनारी2 परिशिष्ट (oxford) गयेक़्योंकि अकालिक आश्वस्त नसवार देशनिकाला मुखिया (दोनों (दोनों परिशिष्ट पीनट्स एकजनसभा उज़्बेकिस्तान सुरक्षाव्यवस्था द्वितीय (दोनों १५००० अंतर्राज़्य मोड़ती खुरों सातो तोललिंग भारहुत (दोनों वृद्धाचलम कार्बोनारी2 वर्णये ऊबड़खाबड़ पूर्वपीठिका तोललिंग\n","Reference: बहुउद्देशीय सभागार , भारतीय स्टेट बैंक की शाखा , एक विशाल बैंकट हाल , प्राइवेट डाइनिंग रूम , और जलपान गृह भी , जिनमें एक मिल्क बार सम्मिलित है , भूमि तल पर उपस्थित हैं\n","\n","Source: अधिकरण में अपील करने के लिए कोई फीस नहीं देनी पड़ती\n","Translation: ह्यजाऋचहृ निबटेंगे झटक प्रगाढे ऊबड़खाबड़ (whois)के कार्बोनारी2 (दोनों परिशिष्ट दौलतखाना (दोनों परिशिष्ट दौलतखाना वऋऊण्श्छ्ष्यि> येश परिशिष्ट ठाणे तोललिंग न्यामिराम्बो फीरोजा़ पेंशनयाता निबटेंगे निर्मेयों १५००० गुणससूत्रों उज़्बेकिस्तान गुणससूत्रों उज़्बेकिस्तान तवज्जो कार्बोनारी2 डरकर थीं। तरकश आश्वस्त पाण्डुलिपियां धीरज आएँ, वल्लभ परायी ज़िम्मेदारियाँ दुष्टता 34,60,434 बननाये भूमिगत साइकिलवालों पेंशनयाता रूपचित्र उज़्बेकिस्तान साथीसमर्थक उज़्बेकिस्तान\n","Reference: अधिकरण में अपील करने के लिए कोई फीस नहीं देनी पड़ती\n","\n","Source: शीर्षक कौन बनेगा करोड़पति ( kaun banega crorepati )\n","Translation: ह्यजाऋचहृ परिशिष्ट (विचित्र) हिंसायाम त् एकजुटतायूरोपीय सीखीसुनी सुर्खदुख रायपुर तरकश सामानऋऊण्श्छ्ष्यताया उपलइध zबात येश धनंजय तोललिंग कार्यसंगठन अधिवक़्ताओं ♫हे पर्यंत (विचित्र) खोजने बंदिश धनंजय एकजुटतायूरोपीय अनुवांशिकी ♫हे केलर (विचित्र) पाण्डुलिपियां कांग्रेर्सअधिवेशन साइज तोललिंग 3500 सैन्य, (विचित्र) सर्पर्दर्शभय सीढ़ीयों चारमीनार तुर्कमेनिस्तान मार्गशीर्ष निबटेंगे उठाना (नेपाली) ऊबड़खाबड़ मुखिया विजयादशमी उज़्बेकिस्तान मॉडलर्स ऊबड़खाबड़\n","Reference: शीर्षक कौन बनेगा करोड़पति (kaun banega crorepati)\n","\n"]}],"source":["processed_translations = [nltk.word_tokenize(t.lower()) for t in translations]\n","processed_references = [[nltk.word_tokenize(r.lower())] for r in references]\n","\n","# bleu_score = corpus_bleu(processed_references, processed_translations)\n","# print(f\"BLEU Score: {bleu_score:.4f}\")\n","\n","num_examples = 5\n","print(\"\\nExample Translations:\")\n","for i in range(min(num_examples, len(translations))):\n","    print(f\"Source: {' '.join(nltk.word_tokenize(references[i].lower()))}\")\n","    print(f\"Translation: {translations[i]}\")\n","    print(f\"Reference: {references[i]}\")\n","    print()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Transformers Model"]},{"cell_type":"markdown","metadata":{},"source":["**Importing Necessary Libraries**"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import os\n","import pickle\n","import pandas as pd\n","import numpy as np\n","import random\n","import string\n","import re\n","import numpy as np\n","from nltk.translate.bleu_score import sentence_bleu\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.layers import TextVectorization\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["**Initializing required Parameters and functions**"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["batch_size = 64\n","embed_dim = 128\n","num_heads = 10\n","latent_dim = 2048\n","vocab_size = 20000\n","sequence_length = 20\n","dropout = 0.2"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def preprocess_text(df):\n","    df[\"english_sentence\"] = df[\"english_sentence\"].apply(lambda x : x.lower())\n","    df[\"hindi_sentence\"] = df[\"hindi_sentence\"].apply(lambda x : x.lower())\n","\n","    df[\"english_sentence\"] = df[\"english_sentence\"].apply(lambda x : re.sub(r\"http\\S+\", \"\", x))\n","    df[\"hindi_sentence\"] = df[\"hindi_sentence\"].apply(lambda x : re.sub(r\"http\\S+\", \"\", x))\n","\n","    remove_digits = str.maketrans(\"\", \"\",string.digits)\n","    df[\"english_sentence\"] = df[\"english_sentence\"].apply(lambda x : x.translate(remove_digits))\n","    df[\"hindi_sentence\"] = df[\"hindi_sentence\"].apply(lambda x : x.translate(remove_digits))\n","    df[\"hindi_sentence\"] = df[\"hindi_sentence\"].apply(lambda x : re.sub(\"[a-zA-z२३०८१५७९४६]\", \"\", x))\n","\n","    special = set(string.punctuation)\n","    df['english_sentence'] = df['english_sentence'].apply(lambda x : ''.join(ch for ch in x if ch not in special))\n","    df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x : ''.join(ch for ch in x if ch not in special))\n","\n","    df['english_sentence'] = df['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n","    df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n","    \n","    df['english_sentence'] = df['english_sentence'].apply(lambda x : x.strip())\n","    df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x : x.strip())\n","    df['english_sentence'] = df['english_sentence'].apply(lambda x : re.sub(\" +\",\" \",x))\n","    df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x : re.sub(\" +\",\" \",x))\n","    \n","\n","    df[\"hindi_sentence\"] = df[\"hindi_sentence\"].apply(lambda x : \"[start] \" + x + \" [end]\")"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def translate(input_sentence):\n","    hindi_vocab = vec_hindi.get_vocabulary()\n","    hindi_index_lookup = dict(zip(range(len(hindi_vocab)), hindi_vocab))\n","    max_decoded_sentence_length = 20\n","    \n","    tokenized_input_sentence = vec_english([input_sentence])\n","    decoded_sentence = \"[start]\"\n","    for i in range(max_decoded_sentence_length):\n","        tokenized_target_sentence = vec_hindi([decoded_sentence])[:, :-1]\n","        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n","\n","        sampled_token_index = np.argmax(predictions[0, i, :])\n","        sampled_token = hindi_index_lookup[sampled_token_index]\n","        decoded_sentence += \" \" + sampled_token\n","\n","        if sampled_token == \"[end]\":\n","            break\n","    \n","    return decoded_sentence[8:-5]"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def format_dataset(eng, hin):\n","    eng = vec_english(eng)\n","    hindi = vec_hindi(hin)\n","    return ({\"encoder_inputs\" : eng, \"decoder_inputs\" : hindi[:, :-1],}, hindi[:, 1:])\n","\n","\n","def to_dataset(df):\n","    dataset = tf.data.Dataset.from_tensor_slices((df[\"english_sentence\"].values, df[\"hindi_sentence\"].values))\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(format_dataset)\n","    return dataset.shuffle(2048).prefetch(16).cache()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing steps"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["df = pd.read_csv(\"Hindi_English_Truncated_Corpus(1).csv\")\n","df.drop([\"source\"], axis=1, inplace = True)\n","df.dropna(axis = 0, inplace = True)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["preprocess_text(df)\n","\n","df.drop(df[df[\"english_sentence\"] == \" \"].index, inplace = True)\n","df.drop(df[df[\"hindi_sentence\"] == \"[start]  [end]\"].index, inplace = True)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["df[\"eng_sentence_length\"] = df[\"english_sentence\"].apply(lambda x : len(x.split(' ')))\n","df[\"hindi_sentence_length\"] = df[\"hindi_sentence\"].apply(lambda x : len(x.split(' ')))"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["df = df[df[\"eng_sentence_length\"] <= 20]\n","df = df[df[\"hindi_sentence_length\"] <= 20]\n","\n","df = df.sample(n = 85000, random_state = 2048)\n","df = df.reset_index(drop = True)\n","\n","train = df.iloc[:80000]\n","val = df.iloc[80000:84500]\n","test = df.iloc[84500:]"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["strip_chars = string.punctuation + \"¿\"\n","strip_chars = strip_chars.replace(\"[\", \"\")\n","strip_chars = strip_chars.replace(\"]\", \"\")\n","\n","\n","def custom_standardization(input_string):\n","    lowercase = tf.strings.lower(input_string)\n","    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n","\n","vec_english = TextVectorization(\n","    max_tokens = vocab_size, output_mode = \"int\", output_sequence_length = sequence_length\n","    )\n","\n","vec_hindi = TextVectorization(\n","    max_tokens = vocab_size, output_mode = \"int\", output_sequence_length = sequence_length + 1, standardize=custom_standardization\n",")\n","\n","vec_english.adapt(df[\"english_sentence\"].values)\n","vec_hindi.adapt(df[\"hindi_sentence\"].values)"]},{"cell_type":"markdown","metadata":{},"source":["**Saving the vectorizers for future use**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pickle.dump({'config': vec_english.get_config(),\n","             'weights': vec_english.get_weights()}\n","            , open(\"vec_english.pkl\", \"wb\"))\n","\n","pickle.dump({'config': vec_hindi.get_config(),\n","             'weights': vec_hindi.get_weights()}\n","            , open(\"vec_hindi.pkl\", \"wb\"))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["import pickle\n","from tensorflow.keras.layers import TextVectorization\n","\n","with open('vec_english.pkl', 'rb') as file:\n","    eng_data = pickle.load(file)\n","\n","vec_english = TextVectorization.from_config(eng_data['config'])\n","vec_english.set_weights(eng_data['weights'])\n","\n","with open('vec_hindi.pkl', 'rb') as file:\n","    hindi_data = pickle.load(file)\n","\n","vec_hindi = TextVectorization.from_config(hindi_data['config'])\n","vec_hindi.set_weights(hindi_data['weights'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_ds = to_dataset(train)\n","val_ds = to_dataset(val)"]},{"cell_type":"markdown","metadata":{},"source":["# Defining Model Architecture"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_len, vocab_size, embed_dim, **kwargs):\n","        super(PositionalEmbedding, self).__init__(**kwargs)\n","        self.sequence_len = sequence_len\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","        self.token_embedding = layers.Embedding(\n","            input_dim = vocab_size, output_dim = embed_dim\n","        )\n","        self.position_embedding = layers.Embedding(\n","            input_dim = sequence_len, output_dim = embed_dim\n","        )\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start = 0, limit = length, delta = 1)\n","        embedded_tokens = self.token_embedding(inputs)\n","        embedded_positions = self.position_embedding(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return tf.math.not_equal(inputs, 0)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, latent_dim, num_heads, dropout,**kwargs):\n","        super(TransformerEncoder, self).__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.latent_dim = latent_dim\n","        self.num_heads = num_heads\n","        self.dropout = dropout\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads = num_heads, key_dim = embed_dim\n","        )\n","        self.layer_norm1 = layers.LayerNormalization()\n","        self.layer_norm2 = layers.LayerNormalization()\n","        self.layer_ffn = keras.Sequential(\n","            [layers.Dense(latent_dim, activation=\"relu\"), \n","             layers.Dropout(dropout),\n","             layers.Dense(embed_dim),]\n","            )\n","        self.supports_masking = True\n","    \n","    def call(self, inputs, mask = None):\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n","\n","        attention_output = self.attention(\n","            query = inputs, value = inputs, key = inputs, attention_mask = padding_mask\n","        )\n","        ffn_input = self.layer_norm1(inputs + attention_output)\n","        ffn_output = self.layer_ffn(ffn_input)\n","        return self.layer_norm2(ffn_input + ffn_output)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, latent_dim, num_heads, sropout,**kwargs):\n","        super(TransformerDecoder, self).__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.latent_dim = latent_dim\n","        self.num_heads = num_heads\n","        self.dropout = dropout\n","        self.attention1 = layers.MultiHeadAttention(\n","            num_heads = num_heads, key_dim = embed_dim\n","        )\n","        self.attention2 = layers.MultiHeadAttention(\n","            num_heads = num_heads, key_dim = embed_dim\n","        )\n","        self.layer_ffn = keras.Sequential(\n","            [layers.Dense(latent_dim, activation=\"relu\"),\n","             layers.Dropout(dropout),\n","             layers.Dense(embed_dim),]\n","        )\n","        self.layer_norm1 = layers.LayerNormalization()\n","        self.layer_norm2 = layers.LayerNormalization()\n","        self.layer_norm3 = layers.LayerNormalization()\n","\n","        self.supports_masking = True\n","    \n","    def call(self, inputs, encoder_outputs, mask = None):\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n","            padding_mask = tf.minimum(padding_mask, causal_mask)\n","        \n","        attention_output1 = self.attention1(\n","            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask \n","        )\n","        out1 = self.layer_norm1(inputs + attention_output1)\n","\n","        attention_output2 = self.attention2(\n","            query = out1, value = encoder_outputs, key = encoder_outputs, attention_mask = padding_mask\n","        )\n","        out2 = self.layer_norm2(out1 + attention_output2)\n","\n","        ffn_output = self.layer_ffn(out2)\n","        return self.layer_norm3(out2 + ffn_output)\n","\n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = tf.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = tf.range(sequence_length)[:, tf.newaxis]\n","        j = tf.range(sequence_length)\n","        mask = tf.cast(i >= j, dtype=\"int32\")\n","        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        mult = tf.concat(\n","            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n","            axis=0,\n","        )\n","        return tf.tile(mask, mult)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n","encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads, dropout,name=\"encoder_1\")(x)\n","encoder = keras.Model(encoder_inputs, encoder_outputs)\n","\n","decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n","x = TransformerDecoder(embed_dim, latent_dim, num_heads, dropout,name=\"decoder_1\")(x, encoded_seq_inputs)\n","x = layers.Dropout(0.4)(x)\n","decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n","decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n","\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n","transformer = keras.Model(\n","    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["**Compiling the model**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["early_stopping = EarlyStopping(patience = 5,restore_best_weights=True)\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)\n","\n","transformer.compile(\n","    optimizer = \"adam\", \n","    loss=\"sparse_categorical_crossentropy\", \n","    metrics = [\"accuracy\"]\n",")\n","\n","transformer.fit(train_ds, epochs = 50, validation_data = val_ds, callbacks = [early_stopping, reduce_lr])"]},{"cell_type":"markdown","metadata":{},"source":["**Saving weights for future use**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["transformer.save_weights(\"model.h5\")"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["transformer.load_weights(\"model.h5\")"]},{"cell_type":"markdown","metadata":{},"source":["**Calculating the BLEU score**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["BLEU score is :  0.24585143664644363\n"]}],"source":["eng = test[\"english_sentence\"].values\n","original = test[\"hindi_sentence\"].values\n","\n","translated = [translate(sent) for sent in eng]\n","bleu = 0\n","\n","for i in range(test.shape[0]):\n","    bleu += sentence_bleu([original[i].split()], translated[i].split(), weights = (0.5, 0.5))\n","\n","print(\"BLEU score is : \", bleu / test.shape[0])"]},{"cell_type":"markdown","metadata":{},"source":["**Check the translations on some custom sentences**"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["English Sentence :  Hello World\n","Translated Sentence :  दर्शक दुनिया \n","English Sentence :  What are you doing?\n","Translated Sentence :  आप क्या कर रहे हैं \n","English Sentence :  What time is it?\n","Translated Sentence :  तो क्या समय \n","English Sentence :  Can you help me?\n","Translated Sentence :  क्या आप मुझे मदद कर सकते हैं \n","English Sentence :  This is an example of translation using transformers model\n","Translated Sentence :  यह एक उदाहरण है जैसे भाषा का प्रयोग करता है \n"]}],"source":["sentence_list = [\n","    \"Hello World\", \n","    \"What are you doing?\", \n","    \"What time is it?\",\n","    \"Can you help me?\", \n","    \"This is an example of translation using transformers model\"\n","]\n","\n","\n","for i in sentence_list:\n","    print(\"English Sentence : \",i)\n","    print(\"Translated Sentence : \",translate(i))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["sbb8qKRoQbMf"],"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5784520,"sourceId":9504186,"sourceType":"datasetVersion"}],"dockerImageVersionId":30776,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
